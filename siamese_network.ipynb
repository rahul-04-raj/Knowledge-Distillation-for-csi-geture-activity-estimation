{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import scipy.io as scipy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spilting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pairs = joblib.load(\"csi_up_pairs_100.joblib\")\n",
    "labels_pairs = joblib.load(\"labels_up_pairs_100.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2, 200, 30), (10000, 2, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi_pairs.shape, labels_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(csi_pairs, labels_pairs))\n",
    "random.shuffle(temp)\n",
    "csi_pairs, labels_pairs = zip(*temp)\n",
    "csi_pairs, labels_pairs = list(csi_pairs), list(labels_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pairs = np.array(csi_pairs)\n",
    "labels_pairs = np.array(labels_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.constant(labels_pairs[:7000])\n",
    "y_test = tf.constant(labels_pairs[7000:8500])\n",
    "y_val = tf.constant(labels_pairs[8500:10000])\n",
    "pair_train = (csi_pairs[:7000])\n",
    "pair_test = (csi_pairs[7000:8500])\n",
    "pair_val = (csi_pairs[8500:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 2, 200, 30), (1500, 2, 200, 30), (1500, 2, 200, 30))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_train.shape, pair_test.shape, pair_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([7000, 2, 1]),\n",
       " TensorShape([1500, 2, 1]),\n",
       " TensorShape([1500, 2, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_val = np.squeeze(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test-1\n",
    "y_val = y_val-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building siamese network...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 200, 30)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 196, 64)              9664      ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 196, 64)              256       ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 98, 64)               0         ['batch_normalization_2[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 94, 128)              41088     ['max_pooling1d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 94, 128)              512       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 47, 128)              0         ['batch_normalization_3[0][0]'\n",
      " g1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['max_pooling1d_3[0][0]']     \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 128)                  0         ['max_pooling1d_3[0][0]']     \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 256)                  0         ['global_average_pooling1d_1[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512)                  131584    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 183104 (715.25 KB)\n",
      "Trainable params: 182720 (713.75 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               153900    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 276)               83076     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236976 (925.69 KB)\n",
      "Trainable params: 236976 (925.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 200, 30)]            0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 200, 30)]            0         []                            \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, 512)                  183104    ['input_5[0][0]',             \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 1024)                 0         ['model_3[0][0]',             \n",
      " )                                                                   'model_3[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 512)                  0         ['concatenate_4[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 512)                  0         ['concatenate_4[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 276)                  236976    ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 552)                  0         ['model_4[0][0]',             \n",
      " )                                                                   'model_4[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 276)                  0         ['concatenate_5[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 276)                  0         ['concatenate_5[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 420080 (1.60 MB)\n",
      "Trainable params: 419696 (1.60 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def encoder():\n",
    "  inp = Input(shape = (200, 30))\n",
    "  c1 = Conv1D(filters = 64, kernel_size = 5, activation = 'relu')(inp)    #   10,8n\n",
    "  b1 = BatchNormalization()(c1)\n",
    "  m1 = MaxPooling1D(2)(b1)\n",
    "  c2 = Conv1D(filters = 128, kernel_size = 5, activation = 'relu')(m1)    #   8,8nDense(512, activation = 'relu')(inp)\n",
    "  b2 = BatchNormalization()(c2)\n",
    "  m2 = MaxPooling1D(2)(b2)\n",
    "\n",
    "  f_avg = GlobalAveragePooling1D()(m2)\n",
    "  f_max = GlobalMaxPooling1D()(m2)\n",
    "\n",
    "  pool = tf.keras.layers.concatenate([f_avg, f_max])\n",
    "  out = Dense(512, activation = 'relu')(pool)\n",
    "  model = tf.keras.Model(inputs = inp, outputs = out)\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def classifier(emb_d):\n",
    "  inp = Input(shape = (emb_d))\n",
    "  d1 = Dense(300, activation = 'relu')(inp)\n",
    "  out = Dense(276, activation = 'sigmoid')(d1)\n",
    "  model = tf.keras.Model(inputs = inp, outputs = out)\n",
    "  model.summary()\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "print(\"[INFO] building siamese network...\")\n",
    "dataS = Input(shape = (200, 30))   #   104\n",
    "dataT = Input(shape = (200, 30))\n",
    "\n",
    "encoder_common = encoder()\n",
    "\n",
    "embedding_source = encoder_common([dataS])#([dataS, pos_encod_inp])\n",
    "embedding_target = encoder_common([dataT])#([dataT, pos_encod_inp])\n",
    "\n",
    "concat = tf.keras.layers.concatenate([embedding_source, embedding_target])\n",
    "\n",
    "#dim = 128\n",
    "d = 512\n",
    "act_classifier = classifier(emb_d = d)#embedding2coordinate_cnn()\n",
    "\n",
    "embedding_s = concat[ : , : d ]\n",
    "embedding_t = concat[ : , d : ]\n",
    "\n",
    "act_s = act_classifier(embedding_s)\n",
    "act_t = act_classifier(embedding_t)\n",
    "\n",
    "act_cat = tf.keras.layers.concatenate([act_s, act_t])\n",
    "act_out_s = act_cat[ : , : 276 ]\n",
    "act_out_t = act_cat[ : , 276 : ]\n",
    "\n",
    "#model = Model(inputs = [dataA, dataB], outputs = [coord_out_a, coord_out_b, mmd])\n",
    "model = Model(inputs = [dataS, dataT], outputs = [act_out_s, act_out_t])  #, S_identity, T_identity , recon_S, recon_T\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] building and compilation complete!\n",
      "\n",
      " Model summary:\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 200, 30)]            0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 200, 30)]            0         []                            \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, 512)                  183104    ['input_5[0][0]',             \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 1024)                 0         ['model_3[0][0]',             \n",
      " )                                                                   'model_3[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 512)                  0         ['concatenate_4[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 512)                  0         ['concatenate_4[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 276)                  236976    ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 552)                  0         ['model_4[0][0]',             \n",
      " )                                                                   'model_4[1][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 276)                  0         ['concatenate_5[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 276)                  0         ['concatenate_5[0][0]']       \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 420080 (1.60 MB)\n",
      "Trainable params: 419696 (1.60 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate = 0.001)\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss = [\"sparse_categorical_crossentropy\", \"sparse_categorical_crossentropy\"], loss_weights = [1., 1.], optimizer= opt)\n",
    "print('[INFO] building and compilation complete!')\n",
    "print('\\n Model summary:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1047717362.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    computeUnits = .all\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "computeUnits = .all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 7.9948 - tf.__operators__.getitem_6_loss: 2.8729 - tf.__operators__.getitem_7_loss: 5.1220WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 5s 60ms/step - loss: 7.9948 - tf.__operators__.getitem_6_loss: 2.8729 - tf.__operators__.getitem_7_loss: 5.1220 - val_loss: 945.0135 - val_tf.__operators__.getitem_6_loss: 312.9904 - val_tf.__operators__.getitem_7_loss: 632.0231\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.7809 - tf.__operators__.getitem_6_loss: 0.1475 - tf.__operators__.getitem_7_loss: 4.6334WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 4.7809 - tf.__operators__.getitem_6_loss: 0.1475 - tf.__operators__.getitem_7_loss: 4.6334 - val_loss: 529.9079 - val_tf.__operators__.getitem_6_loss: 190.5665 - val_tf.__operators__.getitem_7_loss: 339.3414\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6851 - tf.__operators__.getitem_6_loss: 0.0605 - tf.__operators__.getitem_7_loss: 4.6246WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 4.6851 - tf.__operators__.getitem_6_loss: 0.0605 - tf.__operators__.getitem_7_loss: 4.6246 - val_loss: 584.1915 - val_tf.__operators__.getitem_6_loss: 152.0317 - val_tf.__operators__.getitem_7_loss: 432.1598\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6792 - tf.__operators__.getitem_6_loss: 0.0604 - tf.__operators__.getitem_7_loss: 4.6189WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 4.6792 - tf.__operators__.getitem_6_loss: 0.0604 - tf.__operators__.getitem_7_loss: 4.6189 - val_loss: 872.5820 - val_tf.__operators__.getitem_6_loss: 113.5233 - val_tf.__operators__.getitem_7_loss: 759.0586\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6777 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6174WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 4.6777 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6174 - val_loss: 873.5732 - val_tf.__operators__.getitem_6_loss: 91.8986 - val_tf.__operators__.getitem_7_loss: 781.6747\n",
      "Epoch 6/100\n",
      "69/70 [============================>.] - ETA: 0s - loss: 4.6759 - tf.__operators__.getitem_6_loss: 0.0612 - tf.__operators__.getitem_7_loss: 4.6148WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 4.6751 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6148 - val_loss: 869.8480 - val_tf.__operators__.getitem_6_loss: 113.0790 - val_tf.__operators__.getitem_7_loss: 756.7689\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6732 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6129WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 4.6732 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6129 - val_loss: 847.7983 - val_tf.__operators__.getitem_6_loss: 73.5455 - val_tf.__operators__.getitem_7_loss: 774.2527\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6718 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6115WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 5s 66ms/step - loss: 4.6718 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6115 - val_loss: 838.2386 - val_tf.__operators__.getitem_6_loss: 65.5452 - val_tf.__operators__.getitem_7_loss: 772.6934\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.6702 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6099WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 4.6702 - tf.__operators__.getitem_6_loss: 0.0603 - tf.__operators__.getitem_7_loss: 4.6099 - val_loss: 826.4031 - val_tf.__operators__.getitem_6_loss: 70.7647 - val_tf.__operators__.getitem_7_loss: 755.6385\n",
      "Epoch 10/100\n",
      "37/70 [==============>...............] - ETA: 2s - loss: 4.6723 - tf.__operators__.getitem_6_loss: 0.0654 - tf.__operators__.getitem_7_loss: 4.6070"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] training model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      5\u001b[0m     [pair_train[:, \u001b[39m0\u001b[39;49m], pair_train[:, \u001b[39m1\u001b[39;49m]], [y_train[:, \u001b[39m0\u001b[39;49m] , y_train[:, \u001b[39m1\u001b[39;49m] ],  \u001b[39m#pairTrain[:, 1]\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m   validation_data \u001b[39m=\u001b[39;49m ([pair_val[:, \u001b[39m0\u001b[39;49m], pair_val[:, \u001b[39m1\u001b[39;49m]], y_val[:, \u001b[39m0\u001b[39;49m], y_val[:, \u001b[39m1\u001b[39;49m]),\n\u001b[1;32m      7\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     ,batch_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m    \u001b[39m#8192\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m   , callbacks\u001b[39m=\u001b[39;49mcallback\n\u001b[1;32m     10\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=100, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    [pair_train[:, 0], pair_train[:, 1]], [y_train[:, 0] , y_train[:, 1] ],  #pairTrain[:, 1]\n",
    "  validation_data = ([pair_val[:, 0], pair_val[:, 1]], y_val[:, 0], y_val[:, 1]),\n",
    "    epochs=100\n",
    "    ,batch_size = 100    #8192\n",
    "  , callbacks=callback\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 7ms/step - loss: 7.5918 - tf.__operators__.getitem_2_loss: 2.9867 - tf.__operators__.getitem_3_loss: 4.6052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.591821670532227, 2.9866514205932617, 4.605167865753174]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([pair_test[:, 0], pair_test[:, 1]], [y_test[:, 0] , y_test[:, 1] ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
