{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9dc9d1-76fc-419c-8be9-f4ed94dbda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from time import sleep\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177ea7f7-dce2-47c2-b815-c2a743a0edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/rahul_4real/amplitudes_not_padded_E1.json\",\"r\") as file:\n",
    "          amplitudes = json.load(file)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f689160-2d32-4256-ae34-a21374abfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_labels = joblib.load(\"/users/rahul_4real/Downloads/label_activities_E1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05bc20c-2c77-47b9-885e-ce233f822204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 11 11 11]\n"
     ]
    }
   ],
   "source": [
    "np.asarray(activities_labels)\n",
    "print(activities_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9280d-2fea-4378-8f9d-f550e8a1e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8e862-f3b0-4571-a15d-36de59cc1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20654481-1774-430c-b429-240f2f6e338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(amplitudes, activities_labels))\n",
    "random.shuffle(temp)\n",
    "amplitudes, activities_labels = zip(*temp)\n",
    "amplitudes, activities_labels = list(amplitudes), list(activities_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60a2384d-6180-4fa6-959f-06267c629f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_reshaped = []\n",
    "for amplitude in amplitudes:\n",
    "    b = tf.reshape(amplitude, shape = (-1,1))\n",
    "    amplitudes_reshaped.append(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c12bf5-d678-44a0-8b8f-f7fad00aa357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1231, 90)\n"
     ]
    }
   ],
   "source": [
    "for i in amplitudes:\n",
    "    print(np.shape(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9fb9f-5da8-4d26-99fb-f03c16ea31ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8905db-0371-4d29-b869-04f7c294ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4216dccb-1a02-4400-bf88-909d832ff324",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.constant(activities_labels[:2250])\n",
    "y_test = tf.constant(activities_labels[2250:3000])\n",
    "x_train = (amplitudes[:2250])\n",
    "x_test = (amplitudes[2250:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59c83efe-99fd-44ea-9cd9-44b60cea2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.ragged.constant(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53b7f90c-48ca-452d-938a-c022909bd697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.ragged.constant(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a869d37f-25e1-4e43-b0fb-bb0976fc82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.expand_dims(x_train, axis = -1)\n",
    "x_test = tf.expand_dims(x_test, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd471566-9cda-4d17-bf03-aab8eb931460",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.squeeze(x_train)\n",
    "x_test = np.squeeze(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "208a7fb2-24c7-4d59-9e2d-98bc380818dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1402, None])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb562462-6be4-452a-adbb-e0bed84ae25c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2250,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2022\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2024\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2022\u001b[0m     result \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m asarray(a)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2250,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c04eddf9-7b56-47af-bf70-0adc391ff447",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2250,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2022\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2024\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2022\u001b[0m     result \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m asarray(a)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2250,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06762415-f0c7-43ab-9d5e-5c0dfd374d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ts = []\n",
    "for i in range(len(x_train)):\n",
    "    x = np.reshape(x_train[i], ( -1, 1))\n",
    "    x_train_ts.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a507764e-1ba6-4d9f-a860-3234f56c6db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85950, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train_ts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ddc98-cc63-4458-b3f8-588db4a38c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b82bfb-2ece-4f9e-9781-2be9d5b0bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model_1 = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape = (1601, 90,1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f86ef-1cdf-4d0a-83b8-969cc493d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = model_1.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d2d5a-cdf7-4adf-badb-7d997b269a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a04ee6-50af-4637-8ea2-d098907c4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense\n",
    "model_2 = models.Sequential([\n",
    "    layers.Conv1D(filters=32, kernel_size=(3), activation='relu', input_shape = (None, 90)),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.Conv1D(filters=64, kernel_size=(3), activation='relu'),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "model_2.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91801a44-381d-4710-a302-26413e7c89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 6.9653 - accuracy: 0.1156\n",
      "Epoch 2/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 2.4321 - accuracy: 0.1356\n",
      "Epoch 3/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 2.3542 - accuracy: 0.1627\n",
      "Epoch 4/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 2.1719 - accuracy: 0.2191\n",
      "Epoch 5/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 2.0233 - accuracy: 0.2444\n",
      "Epoch 6/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.8844 - accuracy: 0.3298\n",
      "Epoch 7/30\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 1.7780 - accuracy: 0.3582\n",
      "Epoch 8/30\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 1.7407 - accuracy: 0.3804\n",
      "Epoch 9/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.5534 - accuracy: 0.4480\n",
      "Epoch 10/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.4496 - accuracy: 0.4782\n",
      "Epoch 11/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.3754 - accuracy: 0.5133\n",
      "Epoch 12/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.3293 - accuracy: 0.5396\n",
      "Epoch 13/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.1851 - accuracy: 0.5898\n",
      "Epoch 14/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.1255 - accuracy: 0.6160\n",
      "Epoch 15/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 1.0204 - accuracy: 0.6502\n",
      "Epoch 16/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.9425 - accuracy: 0.6742\n",
      "Epoch 17/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.8777 - accuracy: 0.6978\n",
      "Epoch 18/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.8400 - accuracy: 0.7022\n",
      "Epoch 19/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.7373 - accuracy: 0.7493\n",
      "Epoch 20/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.7495 - accuracy: 0.7436\n",
      "Epoch 21/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.6740 - accuracy: 0.7636\n",
      "Epoch 22/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.6235 - accuracy: 0.7876\n",
      "Epoch 23/30\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.6053 - accuracy: 0.7844\n",
      "Epoch 24/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.5434 - accuracy: 0.8160\n",
      "Epoch 25/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.4753 - accuracy: 0.8360\n",
      "Epoch 26/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.5664 - accuracy: 0.8071\n",
      "Epoch 27/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.5125 - accuracy: 0.8267\n",
      "Epoch 28/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.4683 - accuracy: 0.8347\n",
      "Epoch 29/30\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 0.3816 - accuracy: 0.8711\n",
      "Epoch 30/30\n",
      "71/71 [==============================] - 1s 16ms/step - loss: 0.4185 - accuracy: 0.8538\n"
     ]
    }
   ],
   "source": [
    "history_1d_1 = model_2.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eae5ffb-881d-40b5-b9dc-f7f285d99ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 10ms/step - loss: 2.2612 - accuracy: 0.4973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.261240243911743, 0.4973333477973938]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a523afb7-bb98-4495-8fe2-1140ba4ff6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 90)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d648c447-1ea0-4b02-9056-eb868dae48d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2250])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f1e9b7-cc4e-40b7-bf4d-0eae89779e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D, MaxPool1D, Flatten, Dense, GlobalMaxPooling1D, Masking, Input\n\u001b[0;32m----> 4\u001b[0m model_3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# layers.Masking(mask_value = 0.0, input_shape = (None,90), ragged = True),\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# layers.Input([None, 90], dtype=tf.float16, ragged=True),\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;241m90\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPooling1D((\u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     11\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPooling1D((\u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     layers\u001b[38;5;241m.\u001b[39mGlobalMaxPooling1D(),\n\u001b[1;32m     14\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     15\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m12\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m model_3\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     19\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[1;32m     20\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, GlobalMaxPooling1D, Masking, Input\n",
    "model_3 = models.Sequential([\n",
    "    # layers.Masking(mask_value = 0.0, input_shape = (None,90), ragged = True),\n",
    "    # layers.Input([None, 90], dtype=tf.float16, ragged=True),\n",
    "    layers.Conv1D(filters=32, kernel_size=(3), activation='relu', input_shape = (None,90)),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.Conv1D(filters=64, kernel_size=(3), activation='relu'),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3a1aa-b113-495c-95fa-99c444af3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_3.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95640fbe-de0c-4742-adb5-0cb1e986cf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 19ms/step - loss: 0.1079 - accuracy: 0.9573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1079191192984581, 0.9573333263397217]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3506a0-408b-418a-ba07-14aacf0bcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, GlobalAveragePooling1D\n",
    "model_4 = models.Sequential([\n",
    "    layers.Conv1D(filters=32, kernel_size=(3), activation='relu', input_shape = (None, 90)),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.Conv1D(filters=64, kernel_size=(3), activation='relu'),\n",
    "    layers.MaxPooling1D((2)),\n",
    "    \n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "model_4.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4770e12a-a9aa-4fa9-8ad6-f14cb003df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, None, 32)          8672      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, None, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 64)          6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, None, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 64)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19820 (77.42 KB)\n",
      "Trainable params: 19820 (77.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3484b0-1e2e-41c3-a5ad-9eb03212f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_1_1d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_1_1d/assets\n"
     ]
    }
   ],
   "source": [
    "model_2.save(\"saved_trained_model_1_1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57be4509-18ca-4000-95b6-ac1696f82680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_2_1d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_2_1d/assets\n"
     ]
    }
   ],
   "source": [
    "model_3.save(\"saved_trained_model_2_1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ba9ce-db4a-433f-aa87-66b899eef119",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6 = model_4.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "333ddfcb-2c02-4e26-bbb3-f204dba309ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 18ms/step - loss: 0.0815 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08154702931642532, 0.9666666388511658]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e452962e-e655-402e-8bb1-c112dd1bedd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 1599, 32)          8672      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 799, 32)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 797, 64)           6208      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 398, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 64)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19820 (77.42 KB)\n",
      "Trainable params: 19820 (77.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed851e9d-7916-4d7f-8b95-1bcc2a55e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_3_1d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_3_1d/assets\n"
     ]
    }
   ],
   "source": [
    "model_4.save(\"saved_trained_model_3_1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7869c-fc93-414e-8891-09501ee94ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25dacbbd-69f1-4b14-a112-970e49548811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1599, 88, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 799, 44, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 797, 42, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 398, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 534912)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                34234432  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34254028 (130.67 MB)\n",
      "Trainable params: 34254028 (130.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8968d98e-46ca-4dd9-94e9-75efba055a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_1_2d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_trained_model_1_2d/assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(\"saved_trained_model_1_2d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd25d89c-380e-4626-b19f-e7a92243b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape=(None, 90)))\n",
    "\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac5c5008-85fc-4d81-8026-d2b080d5e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 53s 732ms/step - loss: 2.3456 - accuracy: 0.1898\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 53s 743ms/step - loss: 2.2169 - accuracy: 0.2293\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 54s 756ms/step - loss: 2.1104 - accuracy: 0.2738\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 53s 747ms/step - loss: 2.0495 - accuracy: 0.2822\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 54s 755ms/step - loss: 2.0080 - accuracy: 0.3116\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 54s 756ms/step - loss: 1.9382 - accuracy: 0.3404\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 54s 755ms/step - loss: 1.8690 - accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 53s 751ms/step - loss: 1.8223 - accuracy: 0.3702\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 54s 761ms/step - loss: 1.7658 - accuracy: 0.3933\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 54s 755ms/step - loss: 1.7723 - accuracy: 0.3880\n"
     ]
    }
   ],
   "source": [
    "history_5 = model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8c5d14d-dd9f-4a8b-8658-426a9310a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 128)               112128    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113676 (444.05 KB)\n",
      "Trainable params: 113676 (444.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18f3107b-1e5b-4cc0-94d2-864e1c96468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([90])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a56c23be-4404-4cd0-947e-0828f3c44f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 6s 262ms/step - loss: 1.7322 - accuracy: 0.4160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7321996688842773, 0.41600000858306885]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bbe8c7a7-1ad2-4363-80cc-dbbb1f2d8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(GRU(128, input_shape=(None, 90)))\n",
    "\n",
    "model_5.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model_5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "01881739-61c1-46d1-a66a-cd0c6792deb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "71/71 [==============================] - 47s 642ms/step - loss: 2.1914 - accuracy: 0.2360\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 46s 644ms/step - loss: 1.9633 - accuracy: 0.3129\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 45s 634ms/step - loss: 1.8361 - accuracy: 0.3476\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 46s 650ms/step - loss: 1.7515 - accuracy: 0.3764\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 46s 644ms/step - loss: 1.6817 - accuracy: 0.4111\n"
     ]
    }
   ],
   "source": [
    "history_6 = model_5.fit(x_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19a964b8-4c88-4d22-90c9-2bf694c26635",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_5\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_5' is not defined"
     ]
    }
   ],
   "source": [
    "model_5.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7609cc5c-40b7-4361-aaf0-0280f50cbf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 128)               84480     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86028 (336.05 KB)\n",
      "Trainable params: 86028 (336.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32016277-5855-47ca-b91d-0560f59c08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model_6 = Sequential()\n",
    "\n",
    "model_6.add(LSTM(64, input_shape=(None, 90), return_sequences=True))\n",
    "\n",
    "model_6.add(LSTM(32))\n",
    "\n",
    "model_6.add(Dense(12, activation='softmax'))\n",
    "model_6.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e51bc7d-5f24-44d8-bd49-d263302d3e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, None, 64)          39680     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52492 (205.05 KB)\n",
      "Trainable params: 52492 (205.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "700f54a8-9e91-4c6f-81d4-c6d4868744a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 51s 693ms/step - loss: 2.2790 - accuracy: 0.1956\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 50s 702ms/step - loss: 2.0286 - accuracy: 0.2498\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 51s 715ms/step - loss: 1.9624 - accuracy: 0.2840\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 49s 689ms/step - loss: 1.8964 - accuracy: 0.2902\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 50s 698ms/step - loss: 1.8201 - accuracy: 0.3129\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 49s 687ms/step - loss: 1.8406 - accuracy: 0.2858\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 49s 683ms/step - loss: 1.8290 - accuracy: 0.2996\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 49s 685ms/step - loss: 1.8032 - accuracy: 0.3076\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 50s 708ms/step - loss: 1.8247 - accuracy: 0.3227\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 49s 689ms/step - loss: 1.8101 - accuracy: 0.3173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x43c317910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6123278-69b4-4ff6-a4a6-574dc778d249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 5s 178ms/step - loss: 1.6830 - accuracy: 0.3373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6830106973648071, 0.3373333215713501]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7d1b4e-4e19-4942-b0c8-21d28571701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM\n",
    "\n",
    "\n",
    "model_9 = Sequential()\n",
    "\n",
    "model_9.add(LSTM(128, input_shape=(None, 90), return_sequences=True))\n",
    "model_9.add(GRU(64, return_sequences=True))\n",
    "model_9.add(GRU(32))\n",
    "\n",
    "model_9.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model_9.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56ee6a42-cf7c-4541-8f28-7af878352149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 129s 2s/step - loss: 2.1661 - accuracy: 0.2076\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 125s 2s/step - loss: 1.8310 - accuracy: 0.3138\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 122s 2s/step - loss: 1.7918 - accuracy: 0.3142\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 126s 2s/step - loss: 1.6538 - accuracy: 0.3649\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 121s 2s/step - loss: 1.5817 - accuracy: 0.4027\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 122s 2s/step - loss: 1.5089 - accuracy: 0.4138\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 122s 2s/step - loss: 1.4097 - accuracy: 0.4547\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 132s 2s/step - loss: 1.3571 - accuracy: 0.4800\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 141s 2s/step - loss: 1.2943 - accuracy: 0.5004\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 138s 2s/step - loss: 1.3052 - accuracy: 0.5062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17a8d1d90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5398c217-eb77-49bf-8307-eb5b8790ddb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 11s 459ms/step - loss: 1.1122 - accuracy: 0.5560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1121647357940674, 0.5559999942779541]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7243a2e-09b7-4360-8b1f-c57488ee01f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e3d46f8-8c6a-46e3-8daa-72c8164b2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, 1)]         0         \n",
      "                                                                 \n",
      " time_distributed_11 (TimeD  (None, None, 128)         256       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_12 (TimeD  (None, None, 128)         0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " value (TimeDistributed)     (None, None, 128)         16512     \n",
      "                                                                 \n",
      " time_distributed_13 (TimeD  (None, None, 12)          1548      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18316 (71.55 KB)\n",
      "Trainable params: 18316 (71.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "\n",
    "def transformer_mid():\n",
    "    inp = Input(shape=(None, 1))\n",
    "\n",
    "    # Q, K, V (non-linear)\n",
    "    x_k = layers.TimeDistributed(layers.Dense(128, activation='relu'))(inp)\n",
    "    x_k = layers.TimeDistributed(layers.Dropout(0.4))(x_k)\n",
    "    x_k = layers.TimeDistributed(layers.Dense(128, activation='relu'), name='key')(x_k)\n",
    "\n",
    "    x_q = layers.TimeDistributed(layers.Dense(128, activation='relu'))(inp)\n",
    "    x_q = layers.TimeDistributed(layers.Dropout(0.4))(x_q)\n",
    "    x_q = layers.TimeDistributed(layers.Dense(128, activation='relu'), name='query')(x_q)\n",
    "\n",
    "    x_v = layers.TimeDistributed(layers.Dense(128, activation='relu'))(inp)\n",
    "    x_v = layers.TimeDistributed(layers.Dropout(0.4))(x_v)\n",
    "    x_v = layers.TimeDistributed(layers.Dense(128, activation='relu'), name='value')(x_v)\n",
    "\n",
    "    # QKT/sqrt(d_model)\n",
    "    # kqT = tf.linalg.matmul(x_q, x_k, transpose_b=True, name='QKT') * tf.constant(0.176)\n",
    "\n",
    "    # ROW-WISE SOFTMAX\n",
    "    # sfmx = tf.nn.softmax(kqT, axis=1)\n",
    "    # attn = tf.linalg.matmul(sfmx, x_v, name='penultimate')\n",
    "\n",
    "    # FINAL OUTPUT\n",
    "    out = layers.TimeDistributed(layers.Dense(12))(x_v)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "m = transformer_mid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62a5c8a8-726b-4e58-8708-e9b98f9309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8de3904e-f9ad-4b27-bbbc-b62bac1ed110",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 124740, 85950, 115200, 90990, 114570, 114930, 112950, 115110, 84870, 139860, 115020, 109890, 115110, 142920, 114930, 83340, 126810, 111600, 85860, 81900, 114750, 113040, 144000, 112950, 112590, 84150, 144000, 86400, 111600, 110520, 83880, 111870, 113130, 141840, 114480, 86400, 84060, 112050, 85590, 112050, 114390, 90270, 114030, 123660, 114570, 113400, 112770, 112860, 86040, 143550, 112590, 114120, 143820, 114300, 115200, 123750, 111600, 143910, 88110, 114660, 115290, 109800, 115020, 89730, 114750, 92070, 84960, 140400, 125910, 92160, 85320, 113850, 115110, 115200, 86310, 112320, 142290, 137790, 82260, 114750, 113580, 109170, 82890, 114840, 143550, 109260, 84690, 87210, 86400, 110790, 113670, 113310, 112320, 104220, 111420, 108450, 143640, 138150, 114660, 83880, 85320, 113220, 112500, 84420, 113940, 113130, 114660, 90360, 115200, 112410, 114750, 91350, 126540, 85410, 90900, 110340, 84600, 115200, 111690, 115290, 142290, 115110, 112860, 112860, 143640, 85320, 84420, 86760, 112860, 111690, 109890, 111510, 89370, 139770, 84690, 86400, 109980, 113220, 111600, 140670, 114480, 117990, 111150, 112680, 114840, 115020, 114210, 113220, 110700, 138330, 111690, 114480, 115200, 142560, 85950, 82890, 85950, 112500, 112140, 142560, 114840, 110610, 112500, 85770, 114930, 85950, 111330, 87840, 90270, 114840, 111780, 143730, 110520, 115110, 115200, 84690, 115200, 86310, 112500, 89100, 110340, 113040, 85950, 101160, 142020, 143910, 86490, 140310, 114660, 140580, 144000, 111150, 110700, 90000, 110610, 125640, 81360, 130590, 84690, 113580, 92250, 83250, 113310, 112770, 115200, 115290, 111870, 86490, 113580, 114480, 126540, 112770, 119250, 91260, 143820, 141030, 92070, 108090, 113760, 112410, 86220, 112950, 137970, 115290, 143820, 109350, 89730, 114390, 115290, 113670, 123840, 113580, 111690, 142650, 115020, 112050, 91530, 82980, 113580, 115020, 114750, 87210, 115020, 85410, 85410, 113400, 112320, 115110, 108720, 109350, 114390, 111600, 140310, 143190, 125190, 111060, 112950, 112050, 114390, 141390, 86310, 112860, 90630, 115200, 90630, 140400, 114840, 112770, 113220, 90900, 84060, 89010, 134280, 143100, 112770, 143280, 88650, 84690, 113490, 138330, 115110, 114660, 124560, 115020, 90180, 114930, 115200, 113670, 108360, 85140, 115200, 91980, 143550, 109350, 114930, 83700, 84060, 109080, 115110, 111960, 143730, 83520, 105840, 114930, 139770, 113220, 124650, 119160, 91890, 84690, 111420, 139050, 83520, 144000, 108720, 140400, 113040, 111780, 115200, 122400, 141660, 112950, 114750, 115110, 111060, 85050, 85680, 110520, 114300, 110880, 115110, 143010, 139770, 90810, 86310, 142560, 92070, 123300, 110700, 112680, 113940, 84960, 143640, 113400, 114840, 126990, 111510, 108000, 112770, 110970, 114480, 112770, 85230, 139590, 92250, 83610, 139860, 112590, 141480, 113220, 115200, 138960, 84960, 113580, 112500, 112500, 133740, 114930, 114570, 114840, 115200, 109260, 114930, 114120, 83790, 86310, 91800, 120780, 110160, 86490, 113490, 86310, 115110, 83250, 108000, 113760, 143820, 111690, 112590, 115020, 111690, 67860, 137070, 114930, 91620, 114390, 109890, 135270, 114480, 114390, 84420, 112950, 114210, 111780, 105390, 109530, 115200, 110250, 115110, 134190, 125370, 83970, 92070, 86490, 109350, 113130, 111960, 135900, 143640, 83160, 114930, 110520, 115200, 111870, 84690, 112680, 86400, 143910, 115200, 115200, 135900, 111060, 110610, 113940, 113670, 105030, 144090, 114480, 115110, 86220, 111960, 107100, 84330, 92160, 113580, 114390, 110160, 114840, 86130, 109710, 126270, 110700, 115200, 112500, 88560, 143550, 113310, 136170, 111150, 115020, 112140, 112860, 86490, 92250, 114210, 112140, 84060, 124020, 114570, 144000, 142830, 84150, 115200, 85680, 85140, 113040, 85410, 108990, 113940, 113490, 90450, 113400, 126630, 89460, 88560, 115110, 115200, 133290, 110160, 139680, 115200, 140940, 142740, 144090, 91800, 114030, 89910, 89010, 114930, 112770, 84150, 111150, 114030, 113310, 129240, 113850, 115110, 112320, 143550, 77670, 115110, 91980, 113850, 115290, 86130, 114930, 85950, 127260, 85230, 126270, 112500, 125010, 115110, 112680, 113040, 84330, 112680, 143820, 144000, 111870, 114570, 84420, 111690, 84870, 126090, 90090, 92160, 113130, 113130, 112680, 90720, 109800, 143190, 143370, 124290, 140490, 86490, 113490, 85410, 90630, 85050, 137070, 111420, 114930, 111960, 113490, 113130, 90180, 106740, 112590, 144090, 111780, 127890, 115290, 90000, 114300, 139770, 139680, 140760, 110430, 112590, 114930, 111060, 111060, 112410, 92250, 111060, 86130, 125100, 115020, 91260, 136440, 126000, 82170, 91260, 85950, 91980, 111060, 111780, 115200, 91080, 112050, 110250, 115020, 85410, 114210, 110970, 115110, 114930, 90540, 138690, 87300, 126810, 113400, 109260, 143730, 90270, 115110, 143370, 112770, 91800, 90270, 113670, 113400, 112680, 91980, 89910, 89280, 112680, 86310, 115110, 143730, 113310, 113760, 115020, 111600, 82710, 83520, 115290, 85770, 114930, 111060, 111240, 111510, 114120, 112500, 86040, 84330, 114030, 111420, 91260, 110700, 107820, 138150, 115290, 86400, 114120, 92160, 115110, 143370, 115200, 114840, 114480, 86400, 86220, 114750, 92070, 112680, 89730, 126810, 88920, 86400, 85500, 84600, 115110, 118710, 87210, 115020, 114030, 114660, 91620, 113850, 110430, 111510, 142650, 114120, 112320, 113760, 126720, 112500, 84150, 138420, 111330, 109440, 86310, 112410, 111690, 110340, 115200, 121320, 91980, 143550, 115110, 84690, 135990, 86400, 114840, 111870, 105660, 92070, 109980, 141480, 115200, 143370, 140490, 86400, 119970, 90540, 84960, 143100, 143910, 91350, 112050, 91350, 125370, 114930, 143640, 112500, 143730, 84870, 114300, 82440, 91440, 115200, 91890, 85950, 138060, 123480, 114120, 114570, 114480, 110790, 113040, 111510, 112590, 108450, 90900, 112050, 115200, 112770, 115110, 85860, 112500, 114930, 143010, 79920, 113040, 123390, 85500, 91710, 111960, 112320, 114750, 113940, 118890, 86400, 113490, 86490, 114840, 125010, 111240, 139230, 137430, 110610, 114390, 90360, 143820, 111420, 90540, 125820, 139860, 111060, 113220, 111510, 114660, 86310, 85050, 86040, 111060, 90270, 114840, 107910, 85950, 112680, 112050, 109260, 113400, 83520, 91800, 85230, 113040, 111420, 108990, 91710, 89910, 86310, 91980, 115290, 108990, 143640, 115200, 114930, 113130, 140310, 110250, 86850, 128520, 142380, 112950, 89460, 115200, 114300, 84690, 125820, 107190, 114840, 114210, 139320, 137970, 113400, 111780, 86130, 111600, 86940, 115020, 140760, 113130, 115020, 138060, 114390, 112860, 84330, 114750, 91440, 115290, 86310, 106380, 142560, 143460, 115200, 113580, 91710, 85770, 89730, 84780, 115110, 112140, 86580, 113670, 112950, 113490, 112320, 114480, 83610, 87570, 87300, 105300, 112230, 110790, 88740, 84690, 113400, 108810, 112680, 143730, 111690, 114750, 139680, 113580, 114930, 133650, 91440, 115110, 112140, 85320, 140850, 113130, 109890, 88290, 86400, 110970, 81000, 86310, 85140, 137160, 110340, 111780, 113490, 111150, 86220, 90720, 142740, 112320, 115290, 120420, 110880, 114840, 85590, 115110, 90810, 143550, 91440, 113490, 111510, 134820, 125370, 139140, 112680, 90360, 92160, 113130, 114930, 110070, 115020, 92160, 115110, 110790, 115290, 90630, 113850, 115110, 113760, 108900, 141390, 119250, 112860, 110430, 127080, 111600, 83700, 113490, 115020, 113490, 86400, 127890, 82980, 87930, 87210, 112770, 108540, 112860, 142380, 115200, 78390, 115200, 123840, 85590, 111150, 114840, 114390, 84870, 115110, 114840, 114840, 114030, 114120, 116640, 113760, 142740, 85590, 85320, 114930, 91890, 115020, 110880, 109170, 92250, 114300, 84510, 127620, 108720, 114840, 91530, 88650, 114750, 113580, 139860, 115020, 118620, 122850, 92070, 124110, 140130, 85050, 108810, 113310, 110880, 135360, 140220, 113040, 114210, 114570, 87660, 113040, 90000, 125010, 114750, 110970, 139860, 115110, 143820, 92160, 85500, 141030, 112500, 114480, 115020, 85320, 86580, 83880, 112950, 115200, 144000, 111780, 91800, 90540, 114750, 111870, 110700, 140400, 111510, 85770, 115110, 115110, 139860, 112950, 127530, 112230, 111420, 107370, 112140, 114840, 108450, 114030, 86130, 127260, 92070, 91890, 113490, 110970, 142830, 90090, 85320, 112320, 114930, 115020, 115110, 114840, 113130, 113400, 82530, 113400, 108900, 143550, 110340, 114840, 114660, 113490, 112680, 112950, 111690, 143640, 140490, 112320, 143190, 122940, 113670, 88650, 111330, 88920, 109980, 114120, 143640, 114210, 114930, 86130, 90450, 89550, 84870, 111600, 86130, 126090, 111420, 132570, 115290, 110340, 110250, 110430, 139950, 113760, 143910, 115020, 107640, 85140, 86040, 88560, 126450, 115020, 85770, 112050, 85320, 90090, 140490, 113130, 112950, 114120, 105300, 132660, 124740, 112230, 142830, 114570, 91710, 114300, 112230, 113040, 141300, 109800, 110880, 141300, 139860, 112140, 114660, 115200, 114750, 112410, 113130, 140040, 90630, 112410, 84870, 115110, 111960, 85140, 114030, 110070, 143910, 114660, 140760, 114750, 85500, 85230, 89460, 113670, 111240, 107640, 143910, 85950, 110790, 110790, 124200, 115020, 84510, 105930, 110520, 112950, 143820, 113220, 114750, 123030, 113310, 113940, 115020, 92250, 107640, 84420, 115470, 113310, 84780, 106740, 143460, 115380, 91440, 112590, 86310, 84330, 90090, 113130, 85770, 114030, 125640, 92070, 113760, 111870, 92160, 113400, 83520, 107640, 109890, 86400, 140040, 88650, 143910, 110880, 141210, 111240, 142740, 112680, 112500, 115200, 113940, 115290, 113400, 90630, 111780, 115200, 114120, 91710, 132030, 110340, 123750, 112140, 115110, 114660, 112950, 83970, 92160, 112950, 120690, 85500, 143550, 112680, 137520, 112500, 115020, 115200, 111690, 114660, 84600, 142920, 112230, 91890, 139590, 109800, 111960, 84150, 113310, 123660, 111330, 90180, 135900, 86490, 125280, 111600, 86490, 85140, 143730, 139320, 103680, 131490, 109350, 113760, 144090, 114210, 114120, 143910, 91800, 115200, 115110, 114030, 114660, 92070, 113310, 141300, 114120, 85770, 114930, 123120, 114840, 115110, 110070, 125370, 114750, 137880, 138690, 115290, 109980, 84780, 114120, 86220, 114930, 143550, 110340, 110520, 108720, 112500, 114480, 113940, 91980, 114480, 89190, 113850, 112320, 112050, 85680, 113490, 115290, 109890, 92250, 138060, 89460, 126180, 114570, 92070, 106290, 114930, 116100, 111330, 126270, 84240, 85500, 112140, 92160, 83160, 114120, 109980, 114120, 91080, 110700, 114570, 105930, 85770, 86310, 141030, 137700, 91080, 144000, 109890, 90810, 112230, 89100, 112770, 109980, 90540, 112140, 113400, 110520, 92070, 90000, 91890, 86220, 111060, 115290, 91260, 114750, 125730, 114390, 111690, 84960, 85410, 111330, 112950, 109530, 124740, 114840, 113130, 114840, 110790, 134280, 114480, 84690, 115020, 84780, 84690, 141840, 113940, 126630, 112950, 108990, 89730, 84870, 91350, 143280, 126810, 85410, 112050, 116910, 114480, 91980, 109260, 85860, 108810, 112770, 115290, 111690, 115200, 107730, 109530, 110520, 112410, 137340, 125100, 114930, 113490, 89910, 106470, 113310, 139590, 115290, 90270, 115200, 89820, 111600, 142560, 122940, 84060, 114750, 115020, 89280, 77490, 114840, 86130, 113400, 114930, 111240, 114570, 123120, 111870, 115110, 112590, 114660, 111330, 82890, 112950, 108000, 112860, 140490, 140310, 114480, 114660, 86400, 90270, 111690, 109800, 114930, 92160, 123750, 111600, 86400, 127350, 112050, 115110, 88650, 91890, 111600, 114390, 112860, 114390, 114930, 140310, 111870, 110430, 105300, 108270, 111600, 115020, 86220, 127080, 84780, 142920, 115200, 114480, 108540, 106650, 141210, 124920, 114840, 86130, 110970, 125280, 135810, 90360, 111240, 111330, 138960, 112590, 138330, 125910, 114480, 83880, 84690, 143910, 86490, 85680, 85500, 112590, 85500, 139230, 112320, 86130, 108450, 110250, 111240, 114570, 111870, 110880, 92160, 90000, 114120, 85590, 113130, 115200, 91170, 90180, 86760, 141840, 111330, 112410, 113490, 143010, 112140, 121410, 87570, 112860, 140220, 112320, 113400, 110250, 112050, 112950, 85590, 113940, 111780, 111240, 107280, 113040, 114660, 113940, 141300, 115200, 111960, 113310, 114930, 92070, 115200, 91890, 91530, 114120, 89370, 81180, 136980, 85500, 138420, 127530, 89640, 85140, 113940, 82080, 112770, 111870, 113400, 91890, 87930, 138150, 127350, 122040, 139860, 113220, 91980, 88380, 110610, 114300, 119250, 113220, 84510, 113220, 112320, 84960, 86400, 88560, 142200, 114210, 90720, 110250, 111240, 109350, 111960, 112410, 110520, 80460, 139950, 91800, 86490, 124380, 141120, 139950, 115020, 138060, 110340, 115200, 113040, 91890, 143010, 114930, 110430, 109620, 132030, 115020, 108540, 83700, 110970, 125010, 86040, 85500, 143190, 140400, 115290, 85500, 143460, 114660, 84690, 114750, 114840, 113400, 107820, 113580, 106560, 114930, 124200, 114750, 113130, 114480, 84150, 90360, 92070, 113040, 90360, 108270, 108270, 114570, 85410, 86220, 111510, 113400, 86400, 112590, 89550, 85140, 112950, 113040, 113490, 110970, 115110, 113760, 115020, 111240, 128700, 105390, 112410, 86220, 90450, 111600, 115200, 126090, 141750, 113850, 113760, 113580, 113040, 114840, 112140, 112770, 140940, 88560, 111870, 86040, 113310, 140310, 108180, 111150, 88020, 115110, 85770, 114660, 114120, 144000, 113220, 125640, 115290, 92070, 114210, 112140, 126180, 115110, 114840, 110520, 114570, 114660, 111150, 112860, 95220, 124920, 143730, 92160, 112590, 115290, 114210, 138690, 142110, 143460, 115200, 114390, 92160, 89010, 124920, 119700, 82800, 84330, 113040, 137520, 112950, 89280, 115200, 115290, 111510, 143190, 89460, 112500, 113310, 135720, 91980, 113940, 114300, 91080, 140670, 143550, 90270, 115290, 111870, 141030, 115200, 115020, 114390, 140310, 142920, 86490, 137700, 125550, 79020, 142200, 84510, 144000, 83250, 113400, 141120, 85590, 86490, 86310, 112050, 83430, 91800, 115200, 115110, 85590, 115200, 85500, 91530, 111150, 113040, 141570, 115200, 114930, 109080, 113400, 114480, 114030, 86490, 113220, 136620, 92070, 89640, 90990, 91890, 111690, 108450, 143910, 136800, 90000, 115110, 124740, 111780, 139410, 92160, 112680, 135810, 115200, 114480, 114660, 115110, 87480, 115110, 114570, 110790, 143640, 125280, 92070, 140850, 110700, 109980, 110070, 102600, 140040, 91980, 86490, 125550, 92250, 79470, 143100, 85410, 85590, 111690, 88920, 113130, 115200, 110790, 112950, 80910, 88200, 113580, 114120, 84690, 86040, 110880, 108990, 116640, 114570, 91890, 110700, 118710, 91890, 113580, 138870, 113130, 111600, 126990, 111870, 111690, 114480, 110880, 114030, 114750, 141120, 86400, 86400, 85860, 114480, 86490, 113580, 111510, 113400, 85950, 109800, 91980, 79020, 86400, 114210, 112770, 108270, 112410, 91170, 112860, 85590, 90450, 115020, 115020, 110520, 112860, 109980, 115110, 92160, 83520, 111600, 133290, 114570, 112230, 132660, 142110, 113940, 109350, 115290, 115020, 114750, 110610, 125010, 113310, 141300, 140130, 113670, 121680, 84150, 88110, 126270, 86310, 112770, 114660, 109710, 140580, 90720, 115290, 90720, 111060, 127620, 114750, 113760, 114930, 84600, 89370, 137430, 115020, 141210, 118440, 125820, 115110, 84600, 113310, 110610, 126000, 111690, 86310, 92160, 85050, 108630, 126000, 140400, 112500, 111510, 115290, 86130, 84150, 140220, 114660, 137610, 112770, 88830, 143190, 136980, 92160, 112500, 114840, 83790, 83160, 112320, 112770, 114660, 117630, 111960, 114840, 110970, 111960, 115200, 117990, 85230, 113220, 140490, 141390, 115020, 115110, 114030, 112050, 86490, 86400, 112770, 114120, 111600, 114750, 127710, 126990, 90360, 110790, 115020, 126270, 124920, 115110, 92070, 115110, 84870, 109620, 88200, 84780, 115020, 112500, 84960, 91800, 141480, 108450, 115110, 121590, 111870, 112950, 91260, 109890, 86400, 114030, 85860, 88380, 85680, 88830, 114930, 115200, 114750, 114840, 112680, 111420, 92070, 110250, 114750, 143460, 114750, 108360, 112770, 111870, 90000, 113490, 114210, 115200, 114930, 114390, 85770, 112590, 86130, 140400, 113400, 91890, 111600, 90810, 143820, 138780, 89820, 92070, 84960, 86670, 112860, 115200, 85770, 110430, 113850, 116010, 112140, 112590, 86580, 115020, 112410, 92250, 82710, 84060, 111600, 108720, 114210, 111150, 114390, 112950, 125640, 112860, 91890, 114570, 113220, 142470, 112950, 135990, 112680, 114840, 111870, 111690, 91170, 110970, 114930, 110970, 109080, 88200, 90810, 107820, 114750, 115200, 127440, 85050, 114930, 139590, 137880, 114570, 82890, 111690, 111870, 115020, 124560, 85410, 106920, 82350, 138060, 92250, 136440, 104580, 110700, 143910, 124830, 109170, 115020, 114480, 112950, 126720, 125370, 140400, 84330, 143640, 91080, 110160, 110880, 109800, 111150, 123210, 114570, 114030, 115110, 108360, 114930, 144000, 114750, 143460, 143820, 114660, 86490, 111240, 115110, 83070, 119160, 114930, 114930, 112050, 115020, 115110, 143640, 112680, 107910, 112230, 89550, 111240, 124650, 112770, 111600, 91980, 112230, 113490, 84240, 139680, 111510, 86490, 110070, 91800, 143730, 91440, 82350, 115020, 112680, 85410, 92160, 109800, 142290, 90720, 112770, 86490, 113490, 124110, 112500, 115200, 114390, 114840, 112590, 115200, 143280, 115020, 92070, 112140, 114750, 113130, 111330, 110790, 84240, 137520, 114300, 107370, 86220, 87300, 114120, 87210, 89640, 115200, 110880, 110790, 114750, 142380, 113220, 126720, 115200, 125910, 142200, 115110, 115020, 92160, 89910, 137610, 133470, 110160, 86310, 109170, 84510, 126090, 115290, 138510, 85050, 86940, 114930, 109980, 91530, 114930, 143370, 84240, 85770, 112860, 140130, 124920, 135000, 142290, 113220, 112140, 90720, 110880, 115200, 114570, 124110, 115020, 89280, 111960, 140040, 92160, 114930, 113310, 106920, 112950, 111690, 86130, 138600, 111600, 112770, 112680, 134910, 113670, 85410, 114660, 112500, 109080, 114930\n  y sizes: 2250\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 124740, 85950, 115200, 90990, 114570, 114930, 112950, 115110, 84870, 139860, 115020, 109890, 115110, 142920, 114930, 83340, 126810, 111600, 85860, 81900, 114750, 113040, 144000, 112950, 112590, 84150, 144000, 86400, 111600, 110520, 83880, 111870, 113130, 141840, 114480, 86400, 84060, 112050, 85590, 112050, 114390, 90270, 114030, 123660, 114570, 113400, 112770, 112860, 86040, 143550, 112590, 114120, 143820, 114300, 115200, 123750, 111600, 143910, 88110, 114660, 115290, 109800, 115020, 89730, 114750, 92070, 84960, 140400, 125910, 92160, 85320, 113850, 115110, 115200, 86310, 112320, 142290, 137790, 82260, 114750, 113580, 109170, 82890, 114840, 143550, 109260, 84690, 87210, 86400, 110790, 113670, 113310, 112320, 104220, 111420, 108450, 143640, 138150, 114660, 83880, 85320, 113220, 112500, 84420, 113940, 113130, 114660, 90360, 115200, 112410, 114750, 91350, 126540, 85410, 90900, 110340, 84600, 115200, 111690, 115290, 142290, 115110, 112860, 112860, 143640, 85320, 84420, 86760, 112860, 111690, 109890, 111510, 89370, 139770, 84690, 86400, 109980, 113220, 111600, 140670, 114480, 117990, 111150, 112680, 114840, 115020, 114210, 113220, 110700, 138330, 111690, 114480, 115200, 142560, 85950, 82890, 85950, 112500, 112140, 142560, 114840, 110610, 112500, 85770, 114930, 85950, 111330, 87840, 90270, 114840, 111780, 143730, 110520, 115110, 115200, 84690, 115200, 86310, 112500, 89100, 110340, 113040, 85950, 101160, 142020, 143910, 86490, 140310, 114660, 140580, 144000, 111150, 110700, 90000, 110610, 125640, 81360, 130590, 84690, 113580, 92250, 83250, 113310, 112770, 115200, 115290, 111870, 86490, 113580, 114480, 126540, 112770, 119250, 91260, 143820, 141030, 92070, 108090, 113760, 112410, 86220, 112950, 137970, 115290, 143820, 109350, 89730, 114390, 115290, 113670, 123840, 113580, 111690, 142650, 115020, 112050, 91530, 82980, 113580, 115020, 114750, 87210, 115020, 85410, 85410, 113400, 112320, 115110, 108720, 109350, 114390, 111600, 140310, 143190, 125190, 111060, 112950, 112050, 114390, 141390, 86310, 112860, 90630, 115200, 90630, 140400, 114840, 112770, 113220, 90900, 84060, 89010, 134280, 143100, 112770, 143280, 88650, 84690, 113490, 138330, 115110, 114660, 124560, 115020, 90180, 114930, 115200, 113670, 108360, 85140, 115200, 91980, 143550, 109350, 114930, 83700, 84060, 109080, 115110, 111960, 143730, 83520, 105840, 114930, 139770, 113220, 124650, 119160, 91890, 84690, 111420, 139050, 83520, 144000, 108720, 140400, 113040, 111780, 115200, 122400, 141660, 112950, 114750, 115110, 111060, 85050, 85680, 110520, 114300, 110880, 115110, 143010, 139770, 90810, 86310, 142560, 92070, 123300, 110700, 112680, 113940, 84960, 143640, 113400, 114840, 126990, 111510, 108000, 112770, 110970, 114480, 112770, 85230, 139590, 92250, 83610, 139860, 112590, 141480, 113220, 115200, 138960, 84960, 113580, 112500, 112500, 133740, 114930, 114570, 114840, 115200, 109260, 114930, 114120, 83790, 86310, 91800, 120780, 110160, 86490, 113490, 86310, 115110, 83250, 108000, 113760, 143820, 111690, 112590, 115020, 111690, 67860, 137070, 114930, 91620, 114390, 109890, 135270, 114480, 114390, 84420, 112950, 114210, 111780, 105390, 109530, 115200, 110250, 115110, 134190, 125370, 83970, 92070, 86490, 109350, 113130, 111960, 135900, 143640, 83160, 114930, 110520, 115200, 111870, 84690, 112680, 86400, 143910, 115200, 115200, 135900, 111060, 110610, 113940, 113670, 105030, 144090, 114480, 115110, 86220, 111960, 107100, 84330, 92160, 113580, 114390, 110160, 114840, 86130, 109710, 126270, 110700, 115200, 112500, 88560, 143550, 113310, 136170, 111150, 115020, 112140, 112860, 86490, 92250, 114210, 112140, 84060, 124020, 114570, 144000, 142830, 84150, 115200, 85680, 85140, 113040, 85410, 108990, 113940, 113490, 90450, 113400, 126630, 89460, 88560, 115110, 115200, 133290, 110160, 139680, 115200, 140940, 142740, 144090, 91800, 114030, 89910, 89010, 114930, 112770, 84150, 111150, 114030, 113310, 129240, 113850, 115110, 112320, 143550, 77670, 115110, 91980, 113850, 115290, 86130, 114930, 85950, 127260, 85230, 126270, 112500, 125010, 115110, 112680, 113040, 84330, 112680, 143820, 144000, 111870, 114570, 84420, 111690, 84870, 126090, 90090, 92160, 113130, 113130, 112680, 90720, 109800, 143190, 143370, 124290, 140490, 86490, 113490, 85410, 90630, 85050, 137070, 111420, 114930, 111960, 113490, 113130, 90180, 106740, 112590, 144090, 111780, 127890, 115290, 90000, 114300, 139770, 139680, 140760, 110430, 112590, 114930, 111060, 111060, 112410, 92250, 111060, 86130, 125100, 115020, 91260, 136440, 126000, 82170, 91260, 85950, 91980, 111060, 111780, 115200, 91080, 112050, 110250, 115020, 85410, 114210, 110970, 115110, 114930, 90540, 138690, 87300, 126810, 113400, 109260, 143730, 90270, 115110, 143370, 112770, 91800, 90270, 113670, 113400, 112680, 91980, 89910, 89280, 112680, 86310, 115110, 143730, 113310, 113760, 115020, 111600, 82710, 83520, 115290, 85770, 114930, 111060, 111240, 111510, 114120, 112500, 86040, 84330, 114030, 111420, 91260, 110700, 107820, 138150, 115290, 86400, 114120, 92160, 115110, 143370, 115200, 114840, 114480, 86400, 86220, 114750, 92070, 112680, 89730, 126810, 88920, 86400, 85500, 84600, 115110, 118710, 87210, 115020, 114030, 114660, 91620, 113850, 110430, 111510, 142650, 114120, 112320, 113760, 126720, 112500, 84150, 138420, 111330, 109440, 86310, 112410, 111690, 110340, 115200, 121320, 91980, 143550, 115110, 84690, 135990, 86400, 114840, 111870, 105660, 92070, 109980, 141480, 115200, 143370, 140490, 86400, 119970, 90540, 84960, 143100, 143910, 91350, 112050, 91350, 125370, 114930, 143640, 112500, 143730, 84870, 114300, 82440, 91440, 115200, 91890, 85950, 138060, 123480, 114120, 114570, 114480, 110790, 113040, 111510, 112590, 108450, 90900, 112050, 115200, 112770, 115110, 85860, 112500, 114930, 143010, 79920, 113040, 123390, 85500, 91710, 111960, 112320, 114750, 113940, 118890, 86400, 113490, 86490, 114840, 125010, 111240, 139230, 137430, 110610, 114390, 90360, 143820, 111420, 90540, 125820, 139860, 111060, 113220, 111510, 114660, 86310, 85050, 86040, 111060, 90270, 114840, 107910, 85950, 112680, 112050, 109260, 113400, 83520, 91800, 85230, 113040, 111420, 108990, 91710, 89910, 86310, 91980, 115290, 108990, 143640, 115200, 114930, 113130, 140310, 110250, 86850, 128520, 142380, 112950, 89460, 115200, 114300, 84690, 125820, 107190, 114840, 114210, 139320, 137970, 113400, 111780, 86130, 111600, 86940, 115020, 140760, 113130, 115020, 138060, 114390, 112860, 84330, 114750, 91440, 115290, 86310, 106380, 142560, 143460, 115200, 113580, 91710, 85770, 89730, 84780, 115110, 112140, 86580, 113670, 112950, 113490, 112320, 114480, 83610, 87570, 87300, 105300, 112230, 110790, 88740, 84690, 113400, 108810, 112680, 143730, 111690, 114750, 139680, 113580, 114930, 133650, 91440, 115110, 112140, 85320, 140850, 113130, 109890, 88290, 86400, 110970, 81000, 86310, 85140, 137160, 110340, 111780, 113490, 111150, 86220, 90720, 142740, 112320, 115290, 120420, 110880, 114840, 85590, 115110, 90810, 143550, 91440, 113490, 111510, 134820, 125370, 139140, 112680, 90360, 92160, 113130, 114930, 110070, 115020, 92160, 115110, 110790, 115290, 90630, 113850, 115110, 113760, 108900, 141390, 119250, 112860, 110430, 127080, 111600, 83700, 113490, 115020, 113490, 86400, 127890, 82980, 87930, 87210, 112770, 108540, 112860, 142380, 115200, 78390, 115200, 123840, 85590, 111150, 114840, 114390, 84870, 115110, 114840, 114840, 114030, 114120, 116640, 113760, 142740, 85590, 85320, 114930, 91890, 115020, 110880, 109170, 92250, 114300, 84510, 127620, 108720, 114840, 91530, 88650, 114750, 113580, 139860, 115020, 118620, 122850, 92070, 124110, 140130, 85050, 108810, 113310, 110880, 135360, 140220, 113040, 114210, 114570, 87660, 113040, 90000, 125010, 114750, 110970, 139860, 115110, 143820, 92160, 85500, 141030, 112500, 114480, 115020, 85320, 86580, 83880, 112950, 115200, 144000, 111780, 91800, 90540, 114750, 111870, 110700, 140400, 111510, 85770, 115110, 115110, 139860, 112950, 127530, 112230, 111420, 107370, 112140, 114840, 108450, 114030, 86130, 127260, 92070, 91890, 113490, 110970, 142830, 90090, 85320, 112320, 114930, 115020, 115110, 114840, 113130, 113400, 82530, 113400, 108900, 143550, 110340, 114840, 114660, 113490, 112680, 112950, 111690, 143640, 140490, 112320, 143190, 122940, 113670, 88650, 111330, 88920, 109980, 114120, 143640, 114210, 114930, 86130, 90450, 89550, 84870, 111600, 86130, 126090, 111420, 132570, 115290, 110340, 110250, 110430, 139950, 113760, 143910, 115020, 107640, 85140, 86040, 88560, 126450, 115020, 85770, 112050, 85320, 90090, 140490, 113130, 112950, 114120, 105300, 132660, 124740, 112230, 142830, 114570, 91710, 114300, 112230, 113040, 141300, 109800, 110880, 141300, 139860, 112140, 114660, 115200, 114750, 112410, 113130, 140040, 90630, 112410, 84870, 115110, 111960, 85140, 114030, 110070, 143910, 114660, 140760, 114750, 85500, 85230, 89460, 113670, 111240, 107640, 143910, 85950, 110790, 110790, 124200, 115020, 84510, 105930, 110520, 112950, 143820, 113220, 114750, 123030, 113310, 113940, 115020, 92250, 107640, 84420, 115470, 113310, 84780, 106740, 143460, 115380, 91440, 112590, 86310, 84330, 90090, 113130, 85770, 114030, 125640, 92070, 113760, 111870, 92160, 113400, 83520, 107640, 109890, 86400, 140040, 88650, 143910, 110880, 141210, 111240, 142740, 112680, 112500, 115200, 113940, 115290, 113400, 90630, 111780, 115200, 114120, 91710, 132030, 110340, 123750, 112140, 115110, 114660, 112950, 83970, 92160, 112950, 120690, 85500, 143550, 112680, 137520, 112500, 115020, 115200, 111690, 114660, 84600, 142920, 112230, 91890, 139590, 109800, 111960, 84150, 113310, 123660, 111330, 90180, 135900, 86490, 125280, 111600, 86490, 85140, 143730, 139320, 103680, 131490, 109350, 113760, 144090, 114210, 114120, 143910, 91800, 115200, 115110, 114030, 114660, 92070, 113310, 141300, 114120, 85770, 114930, 123120, 114840, 115110, 110070, 125370, 114750, 137880, 138690, 115290, 109980, 84780, 114120, 86220, 114930, 143550, 110340, 110520, 108720, 112500, 114480, 113940, 91980, 114480, 89190, 113850, 112320, 112050, 85680, 113490, 115290, 109890, 92250, 138060, 89460, 126180, 114570, 92070, 106290, 114930, 116100, 111330, 126270, 84240, 85500, 112140, 92160, 83160, 114120, 109980, 114120, 91080, 110700, 114570, 105930, 85770, 86310, 141030, 137700, 91080, 144000, 109890, 90810, 112230, 89100, 112770, 109980, 90540, 112140, 113400, 110520, 92070, 90000, 91890, 86220, 111060, 115290, 91260, 114750, 125730, 114390, 111690, 84960, 85410, 111330, 112950, 109530, 124740, 114840, 113130, 114840, 110790, 134280, 114480, 84690, 115020, 84780, 84690, 141840, 113940, 126630, 112950, 108990, 89730, 84870, 91350, 143280, 126810, 85410, 112050, 116910, 114480, 91980, 109260, 85860, 108810, 112770, 115290, 111690, 115200, 107730, 109530, 110520, 112410, 137340, 125100, 114930, 113490, 89910, 106470, 113310, 139590, 115290, 90270, 115200, 89820, 111600, 142560, 122940, 84060, 114750, 115020, 89280, 77490, 114840, 86130, 113400, 114930, 111240, 114570, 123120, 111870, 115110, 112590, 114660, 111330, 82890, 112950, 108000, 112860, 140490, 140310, 114480, 114660, 86400, 90270, 111690, 109800, 114930, 92160, 123750, 111600, 86400, 127350, 112050, 115110, 88650, 91890, 111600, 114390, 112860, 114390, 114930, 140310, 111870, 110430, 105300, 108270, 111600, 115020, 86220, 127080, 84780, 142920, 115200, 114480, 108540, 106650, 141210, 124920, 114840, 86130, 110970, 125280, 135810, 90360, 111240, 111330, 138960, 112590, 138330, 125910, 114480, 83880, 84690, 143910, 86490, 85680, 85500, 112590, 85500, 139230, 112320, 86130, 108450, 110250, 111240, 114570, 111870, 110880, 92160, 90000, 114120, 85590, 113130, 115200, 91170, 90180, 86760, 141840, 111330, 112410, 113490, 143010, 112140, 121410, 87570, 112860, 140220, 112320, 113400, 110250, 112050, 112950, 85590, 113940, 111780, 111240, 107280, 113040, 114660, 113940, 141300, 115200, 111960, 113310, 114930, 92070, 115200, 91890, 91530, 114120, 89370, 81180, 136980, 85500, 138420, 127530, 89640, 85140, 113940, 82080, 112770, 111870, 113400, 91890, 87930, 138150, 127350, 122040, 139860, 113220, 91980, 88380, 110610, 114300, 119250, 113220, 84510, 113220, 112320, 84960, 86400, 88560, 142200, 114210, 90720, 110250, 111240, 109350, 111960, 112410, 110520, 80460, 139950, 91800, 86490, 124380, 141120, 139950, 115020, 138060, 110340, 115200, 113040, 91890, 143010, 114930, 110430, 109620, 132030, 115020, 108540, 83700, 110970, 125010, 86040, 85500, 143190, 140400, 115290, 85500, 143460, 114660, 84690, 114750, 114840, 113400, 107820, 113580, 106560, 114930, 124200, 114750, 113130, 114480, 84150, 90360, 92070, 113040, 90360, 108270, 108270, 114570, 85410, 86220, 111510, 113400, 86400, 112590, 89550, 85140, 112950, 113040, 113490, 110970, 115110, 113760, 115020, 111240, 128700, 105390, 112410, 86220, 90450, 111600, 115200, 126090, 141750, 113850, 113760, 113580, 113040, 114840, 112140, 112770, 140940, 88560, 111870, 86040, 113310, 140310, 108180, 111150, 88020, 115110, 85770, 114660, 114120, 144000, 113220, 125640, 115290, 92070, 114210, 112140, 126180, 115110, 114840, 110520, 114570, 114660, 111150, 112860, 95220, 124920, 143730, 92160, 112590, 115290, 114210, 138690, 142110, 143460, 115200, 114390, 92160, 89010, 124920, 119700, 82800, 84330, 113040, 137520, 112950, 89280, 115200, 115290, 111510, 143190, 89460, 112500, 113310, 135720, 91980, 113940, 114300, 91080, 140670, 143550, 90270, 115290, 111870, 141030, 115200, 115020, 114390, 140310, 142920, 86490, 137700, 125550, 79020, 142200, 84510, 144000, 83250, 113400, 141120, 85590, 86490, 86310, 112050, 83430, 91800, 115200, 115110, 85590, 115200, 85500, 91530, 111150, 113040, 141570, 115200, 114930, 109080, 113400, 114480, 114030, 86490, 113220, 136620, 92070, 89640, 90990, 91890, 111690, 108450, 143910, 136800, 90000, 115110, 124740, 111780, 139410, 92160, 112680, 135810, 115200, 114480, 114660, 115110, 87480, 115110, 114570, 110790, 143640, 125280, 92070, 140850, 110700, 109980, 110070, 102600, 140040, 91980, 86490, 125550, 92250, 79470, 143100, 85410, 85590, 111690, 88920, 113130, 115200, 110790, 112950, 80910, 88200, 113580, 114120, 84690, 86040, 110880, 108990, 116640, 114570, 91890, 110700, 118710, 91890, 113580, 138870, 113130, 111600, 126990, 111870, 111690, 114480, 110880, 114030, 114750, 141120, 86400, 86400, 85860, 114480, 86490, 113580, 111510, 113400, 85950, 109800, 91980, 79020, 86400, 114210, 112770, 108270, 112410, 91170, 112860, 85590, 90450, 115020, 115020, 110520, 112860, 109980, 115110, 92160, 83520, 111600, 133290, 114570, 112230, 132660, 142110, 113940, 109350, 115290, 115020, 114750, 110610, 125010, 113310, 141300, 140130, 113670, 121680, 84150, 88110, 126270, 86310, 112770, 114660, 109710, 140580, 90720, 115290, 90720, 111060, 127620, 114750, 113760, 114930, 84600, 89370, 137430, 115020, 141210, 118440, 125820, 115110, 84600, 113310, 110610, 126000, 111690, 86310, 92160, 85050, 108630, 126000, 140400, 112500, 111510, 115290, 86130, 84150, 140220, 114660, 137610, 112770, 88830, 143190, 136980, 92160, 112500, 114840, 83790, 83160, 112320, 112770, 114660, 117630, 111960, 114840, 110970, 111960, 115200, 117990, 85230, 113220, 140490, 141390, 115020, 115110, 114030, 112050, 86490, 86400, 112770, 114120, 111600, 114750, 127710, 126990, 90360, 110790, 115020, 126270, 124920, 115110, 92070, 115110, 84870, 109620, 88200, 84780, 115020, 112500, 84960, 91800, 141480, 108450, 115110, 121590, 111870, 112950, 91260, 109890, 86400, 114030, 85860, 88380, 85680, 88830, 114930, 115200, 114750, 114840, 112680, 111420, 92070, 110250, 114750, 143460, 114750, 108360, 112770, 111870, 90000, 113490, 114210, 115200, 114930, 114390, 85770, 112590, 86130, 140400, 113400, 91890, 111600, 90810, 143820, 138780, 89820, 92070, 84960, 86670, 112860, 115200, 85770, 110430, 113850, 116010, 112140, 112590, 86580, 115020, 112410, 92250, 82710, 84060, 111600, 108720, 114210, 111150, 114390, 112950, 125640, 112860, 91890, 114570, 113220, 142470, 112950, 135990, 112680, 114840, 111870, 111690, 91170, 110970, 114930, 110970, 109080, 88200, 90810, 107820, 114750, 115200, 127440, 85050, 114930, 139590, 137880, 114570, 82890, 111690, 111870, 115020, 124560, 85410, 106920, 82350, 138060, 92250, 136440, 104580, 110700, 143910, 124830, 109170, 115020, 114480, 112950, 126720, 125370, 140400, 84330, 143640, 91080, 110160, 110880, 109800, 111150, 123210, 114570, 114030, 115110, 108360, 114930, 144000, 114750, 143460, 143820, 114660, 86490, 111240, 115110, 83070, 119160, 114930, 114930, 112050, 115020, 115110, 143640, 112680, 107910, 112230, 89550, 111240, 124650, 112770, 111600, 91980, 112230, 113490, 84240, 139680, 111510, 86490, 110070, 91800, 143730, 91440, 82350, 115020, 112680, 85410, 92160, 109800, 142290, 90720, 112770, 86490, 113490, 124110, 112500, 115200, 114390, 114840, 112590, 115200, 143280, 115020, 92070, 112140, 114750, 113130, 111330, 110790, 84240, 137520, 114300, 107370, 86220, 87300, 114120, 87210, 89640, 115200, 110880, 110790, 114750, 142380, 113220, 126720, 115200, 125910, 142200, 115110, 115020, 92160, 89910, 137610, 133470, 110160, 86310, 109170, 84510, 126090, 115290, 138510, 85050, 86940, 114930, 109980, 91530, 114930, 143370, 84240, 85770, 112860, 140130, 124920, 135000, 142290, 113220, 112140, 90720, 110880, 115200, 114570, 124110, 115020, 89280, 111960, 140040, 92160, 114930, 113310, 106920, 112950, 111690, 86130, 138600, 111600, 112770, 112680, 134910, 113670, 85410, 114660, 112500, 109080, 114930\n  y sizes: 2250\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "m.fit(x_train_ts, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0a4fe4d-09e2-4466-8020-c30115874287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([110790, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e2eec4f-24b6-49fb-8df6-a001726dc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(GRU(128, input_shape=(None, 90), return_sequences=True))\n",
    "model_10.add(layers.TimeDistributed(layers.Dense(64, activation='relu')))\n",
    "model_10.add(layers.TimeDistributed(layers.Dense(32, activation='relu')))\n",
    "\n",
    "\n",
    "model_10.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model_10.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6166693c-a80e-428c-9eea-4bda808ed56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_24 (GRU)                (None, None, 128)         84480     \n",
      "                                                                 \n",
      " time_distributed_32 (TimeD  (None, None, 64)          8256      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_33 (TimeD  (None, None, 32)          2080      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, None, 12)          396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95212 (371.92 KB)\n",
      "Trainable params: 95212 (371.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da6cb151-de46-40cc-946a-91a6d11de0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1131, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 713, in update_state  **\n        ], sample_weight = metrics_utils.ragged_assert_compatible_and_get_flat_values(  # noqa: E501\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 872, in ragged_assert_compatible_and_get_flat_values\n        raise TypeError(\n\n    TypeError: Some of the inputs are not tf.RaggedTensor. Input received: [<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>, tf.RaggedTensor(values=Tensor(\"sequential_28/dense_39/Softmax:0\", shape=(None, 12), dtype=float32), row_splits=Tensor(\"sequential_28/time_distributed_30/RaggedFromRowLengths/control_dependency:0\", shape=(None,), dtype=int64))]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/pv/wvqp_ty90s5dnpzrbzh6mkt00000gn/T/__autograph_generated_filepu6j985r.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1131, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/metrics/base_metric.py\", line 713, in update_state  **\n        ], sample_weight = metrics_utils.ragged_assert_compatible_and_get_flat_values(  # noqa: E501\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/metrics_utils.py\", line 872, in ragged_assert_compatible_and_get_flat_values\n        raise TypeError(\n\n    TypeError: Some of the inputs are not tf.RaggedTensor. Input received: [<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>, tf.RaggedTensor(values=Tensor(\"sequential_28/dense_39/Softmax:0\", shape=(None, 12), dtype=float32), row_splits=Tensor(\"sequential_28/time_distributed_30/RaggedFromRowLengths/control_dependency:0\", shape=(None,), dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "model_10.fit(x_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71f32b-2ce3-4bc9-90f2-4e8b4cf2f64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
